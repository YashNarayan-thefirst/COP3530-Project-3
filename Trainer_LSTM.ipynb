{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f984624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9242294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Date','Open','High','Low','Close','Volume',\n",
    "                'Dividends','Stock Splits','Brand_Name','Ticker',\n",
    "                'Industry_Tag','Country','Capital Gains']\n",
    "\n",
    "dataset = pd.read_csv('World-Stock-Prices-Dataset.csv', names=column_names, header=0, na_values='?')\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Day'] = dataset['Date'].dt.day\n",
    "dataset = dataset.dropna(subset=['Close'])\n",
    "\n",
    "feature_columns = ['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits', 'Year', 'Month', 'Day']\n",
    "target_column = 'Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num = scaler.fit_transform(train_dataset[feature_columns])\n",
    "X_test_num = scaler.transform(test_dataset[feature_columns])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X_train_cat = label_encoder.fit_transform(train_dataset['Ticker'])\n",
    "X_test_cat = label_encoder.transform(test_dataset['Ticker'])\n",
    "num_tickers = len(label_encoder.classes_)\n",
    "\n",
    "y_train = train_dataset[target_column].values\n",
    "y_test = test_dataset[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_seq = X_train_num.reshape((-1, 1, len(feature_columns)))\n",
    "X_test_num_seq = X_test_num.reshape((-1, 1, len(feature_columns)))\n",
    "\n",
    "embedding_dim = int(min(50, (num_tickers // 2)**0.25))\n",
    "embedding_dim = max(1, embedding_dim)\n",
    "\n",
    "numerical_input = layers.Input(shape=(1, len(feature_columns)), name='num_input')  \n",
    "ticker_input = layers.Input(shape=(1,), name='ticker_input')\n",
    "\n",
    "ticker_embedding = layers.Embedding(\n",
    "    input_dim=num_tickers + 1,\n",
    "    output_dim=embedding_dim,\n",
    "    name='ticker_embedding'\n",
    ")(ticker_input)\n",
    "ticker_flatten = layers.Flatten()(ticker_embedding)\n",
    "\n",
    "x = layers.LSTM(64, return_sequences=False)(numerical_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "merged = layers.Concatenate()([x, ticker_flatten])\n",
    "\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(merged)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "output = layers.Dense(1, dtype='float32')(x)\n",
    "model = tf.keras.Model(inputs=[numerical_input, ticker_input], outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63370fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_absolute_error',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    x={'num_input': X_train_num_seq, 'ticker_input': X_train_cat},\n",
    "    y=y_train,\n",
    "    batch_size=2048,\n",
    "    epochs=100,\n",
    "    validation_data=(\n",
    "        {'num_input': X_test_num_seq, 'ticker_input': X_test_cat},\n",
    "        y_test\n",
    "    ),\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(\"model_keras_native_lstm.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
